{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp torch_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Utils\n",
    "> Some useful utils to extend pytorch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class InfiniteDl():\n",
    "    def __init__(self, dl):\n",
    "        self.dl = dl\n",
    "        self.it = iter(self.dl)\n",
    "    def next(self):\n",
    "        try:\n",
    "            return self.it.next()\n",
    "        except StopIteration:\n",
    "            self.it = iter(self.dl)\n",
    "            return self.it.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def isin(t, ids):\n",
    "    ''' Returns ByteTensor where True values are positions that contain ids. '''\n",
    "    return (t[..., None] == torch.tensor(ids, device=t.device)).any(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[12, 11, 0, 0], \n",
    "                  [9, 1, 5, 0]])\n",
    "mask = isin(t, [0, 1])\n",
    "test_eq(mask, torch.tensor([[0, 0, 1, 1],\n",
    "                            [0, 1, 0, 1]]).bool())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_src_mask(cap_len, max_seq_len, device='cpu'):\n",
    "    ''' cap_len: (bs,), max_seq_len: int '''\n",
    "    return torch.arange(max_seq_len, device=device)[None, :] >= cap_len[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_len = torch.tensor([2, 1, 3])\n",
    "max_seq_len = 5\n",
    "src_mask = get_src_mask(cap_len, max_seq_len)\n",
    "test_eq(src_mask, torch.tensor([[False, False,  True,  True,  True],\n",
    "                                [False,  True,  True,  True,  True],\n",
    "                                [False, False, False,  True,  True]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Normalizer():\n",
    "    \" normalize input image to -1 ~ 1 \"\n",
    "    def __init__(self, device='cpu'): \n",
    "        self.mean = torch.tensor([0.5, 0.5, 0.5], device=device)[None, ..., None, None] # (1, 3, 1, 1)\n",
    "        self.std = torch.tensor([0.5, 0.5, 0.5], device=device)[None, ..., None, None]\n",
    "    def set_device(device='cpu'):\n",
    "        self.mean.to(device)\n",
    "        self.std.to(device)\n",
    "    def encode(self, x): \n",
    "        \"x: (bs, 3, _, _)\"\n",
    "        return (x.float()/255-self.mean) / self.std\n",
    "    def decode(self, x):\n",
    "        x = x*self.std + self.mean\n",
    "        return (x.clamp(0., 1.)*255).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "img = torch.randint(0, 255, (2, 3, 16, 16))\n",
    "img_encoded = normalizer.encode(img)\n",
    "img_decoded = normalizer.decode(img_encoded)\n",
    "test_close(img, img_decoded, eps=2)\n",
    "\n",
    "# test encoded img is in range -1~1\n",
    "test_eq((img_encoded>=-1).long() + (img_encoded<=1).long(), torch.ones(2, 3, 16, 16).long()*2 )\n",
    "# test decoded img is in range 0~255\n",
    "test_eq((img_decoded>=0).long() + (img_decoded<=255).long(), torch.ones(2, 3, 16, 16).long()*2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def to_device(tensors, device='cpu'):\n",
    "    return [t.to(device) for t in tensors]\n",
    "def detach(tensors, is_to_cpu=False):\n",
    "    return [t.cpu().detach() if is_to_cpu else t.detach() for t in tensors]\n",
    "def is_models_equal(model_1, model_2):\n",
    "    models_differ = 0\n",
    "    for key_item_1, key_item_2 in zip(model_1.state_dict().items(), model_2.state_dict().items()):\n",
    "        if torch.equal(key_item_1[1], key_item_2[1]):\n",
    "            pass\n",
    "        else:\n",
    "            models_differ += 1\n",
    "            if (key_item_1[0] == key_item_2[0]):\n",
    "                print('Mismtach found at', key_item_1[0])\n",
    "                return False\n",
    "            else:\n",
    "                print('Oops somethings wrong')\n",
    "                return False\n",
    "    if models_differ == 0:\n",
    "        return True\n",
    "class MultiWrapper(nn.Module):\n",
    "    def __init__(self, layer, n_returns=1):\n",
    "        super().__init__()\n",
    "        assert n_returns>=1\n",
    "        self.layer = layer\n",
    "        self.n_returns = n_returns\n",
    "    def forward(self, x, *others):\n",
    "        if self.n_returns==1: \n",
    "            return self.layer(x)\n",
    "        else:\n",
    "            return (self.layer(x), *others[:self.n_returns-1])\n",
    "class MultiSequential(nn.Sequential):\n",
    "    def forward(self, *inputs):\n",
    "        for module in self._modules.values():\n",
    "            if type(inputs) == tuple:\n",
    "                inputs = module(*inputs)\n",
    "            else:\n",
    "                inputs = module(inputs)\n",
    "        return inputs\n",
    "class IdentityModule(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "noise_gen = torch.distributions.normal.Normal(0, torch.exp(torch.tensor(-1/np.pi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = noise_gen.sample((2, 100))\n",
    "test_eq(noise.shape, (2, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_torch_utils.ipynb.\n",
      "Converted 02a_data_anime_heads.ipynb.\n",
      "Converted 02b_data_birds.ipynb.\n",
      "Converted 03a_model.ipynb.\n",
      "Converted 04a_trainer_DAMSM.ipynb.\n",
      "Converted 04b_trainer.ipynb.\n",
      "Converted 05a_inference_anime_heads.ipynb.\n",
      "Converted 05b_inference_birds.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
